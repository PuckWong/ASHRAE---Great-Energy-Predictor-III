{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_rows', 200)\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv',\n",
       " 'building_metadata.csv',\n",
       " 'train.csv',\n",
       " 'weather_test.csv',\n",
       " 'sample_submission.csv',\n",
       " 'weather_train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/kaggle/input/ashrae-energy-prediction'\n",
    "os.listdir(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "usecols = ['site_id', 'timestamp', 'air_temperature', 'cloud_coverage',\n",
    "       'dew_temperature', 'precip_depth_1_hr']\n",
    "weather_train = pd.read_csv(directory+'/weather_train.csv', parse_dates=['timestamp'], usecols=usecols)\n",
    "weather_test = pd.read_csv(directory+'/weather_test.csv', parse_dates=['timestamp'], usecols=usecols)\n",
    "weather = pd.concat([weather_train, weather_test])\n",
    "del weather_train, weather_test\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "site_ids_offsets = pd.DataFrame({'site_id': \n",
    "                                 {0: 5,\n",
    "                                  1: 0,\n",
    "                                  2: 9,\n",
    "                                  3: 6,\n",
    "                                  4: 8,\n",
    "                                  5: 0,\n",
    "                                  6: 6,\n",
    "                                  7: 6,\n",
    "                                  8: 5,\n",
    "                                  9: 7,\n",
    "                                  10: 8,\n",
    "                                  11: 6,\n",
    "                                  12: 0,\n",
    "                                  13: 7,\n",
    "                                  14: 6,\n",
    "                                  15: 6}})\n",
    "\n",
    "weather['offset'] = weather['site_id'].map(site_ids_offsets['site_id'])\n",
    "weather['timestamp'] = (weather['timestamp'] - pd.to_timedelta(weather['offset'], unit='H'))\n",
    "del weather['offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_metadata = pd.read_csv(directory+'/building_metadata.csv')\n",
    "building_metadata['primary_use'] = building_metadata['primary_use'].map(dict(zip(building_metadata['primary_use'].unique(), \n",
    "                                                                                 range(16))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(directory+'/train.csv', parse_dates=['timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 22.27 MB\n",
      "Memory usage after optimization is: 13.12 MB\n",
      "Decreased by 41.1%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 66.5%\n"
     ]
    }
   ],
   "source": [
    "weather = reduce_mem_usage(weather)\n",
    "building_metadata = reduce_mem_usage(building_metadata)\n",
    "df_train = df_train.merge(building_metadata, on='building_id', how='left')\n",
    "df_train = df_train.merge(weather, on=['site_id', 'timestamp'], how='left')\n",
    "df_train = df_train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.to_pickle('weather.pkl')\n",
    "building_metadata.to_pickle('building.pkl')\n",
    "del weather, building_metadata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['air_temperature'].notnull()|df_train['cloud_coverage'].notnull()|df_train['dew_temperature'].notnull()|df_train['precip_depth_1_hr'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"hour\"] = df_train[\"timestamp\"].dt.hour\n",
    "df_train[\"weekend\"] = df_train[\"timestamp\"].dt.weekday\n",
    "df_train['year_built'] = df_train['year_built']-1900\n",
    "df_train['square_feet'] = np.log1p(df_train['square_feet'])\n",
    "\n",
    "dates_range = pd.date_range(start='2015-12-31', end='2019-01-01')\n",
    "us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n",
    "df_train['is_holiday'] = (df_train['timestamp'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "del df_train[\"timestamp\"]\n",
    "\n",
    "df_train['meter_reading'] = np.log1p(df_train['meter_reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1414.76 MB\n",
      "Memory usage after optimization is: 754.54 MB\n",
      "Decreased by 46.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "category = ['hour','meter','weekend','primary_use','site_id','building_id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# force the model to use the weather data instead of dates, to avoid overfitting to the past history\n",
    "features = [col for col in df_train.columns if col not in ['meter_reading']]\n",
    "target = 'meter_reading'\n",
    "\n",
    "df_train = df_train[~df_train['meter_reading'].isnull()].reset_index(drop=True)\n",
    "df_train['meter_reading'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold : 0\n",
      "{'train size': 9889878, 'eval size': 9889879}\n",
      "0:\tlearn: 1.9835591\ttest: 1.9793084\tbest: 1.9793084 (0)\ttotal: 1.07s\tremaining: 26m 45s\n",
      "20:\tlearn: 1.1776762\ttest: 1.3186642\tbest: 1.3186642 (20)\ttotal: 21.8s\tremaining: 25m 34s\n",
      "40:\tlearn: 1.0809903\ttest: 1.2535898\tbest: 1.2535898 (40)\ttotal: 41.7s\tremaining: 24m 43s\n",
      "60:\tlearn: 1.0374483\ttest: 1.2260811\tbest: 1.2260811 (60)\ttotal: 1m 3s\tremaining: 24m 46s\n",
      "80:\tlearn: 1.0032288\ttest: 1.2072036\tbest: 1.2072036 (80)\ttotal: 1m 24s\tremaining: 24m 37s\n",
      "100:\tlearn: 0.9813128\ttest: 1.1964487\tbest: 1.1957657 (99)\ttotal: 1m 45s\tremaining: 24m 25s\n",
      "120:\tlearn: 0.9619407\ttest: 1.1874266\tbest: 1.1874266 (120)\ttotal: 2m 8s\tremaining: 24m 20s\n",
      "140:\tlearn: 0.9462669\ttest: 1.1799867\tbest: 1.1799867 (140)\ttotal: 2m 32s\tremaining: 24m 25s\n",
      "160:\tlearn: 0.9323376\ttest: 1.1748415\tbest: 1.1748415 (160)\ttotal: 2m 54s\tremaining: 24m 10s\n",
      "180:\tlearn: 0.9191027\ttest: 1.1703283\tbest: 1.1701577 (179)\ttotal: 3m 17s\tremaining: 23m 59s\n",
      "200:\tlearn: 0.9101628\ttest: 1.1674482\tbest: 1.1671608 (198)\ttotal: 3m 37s\tremaining: 23m 27s\n",
      "220:\tlearn: 0.8995215\ttest: 1.1642219\tbest: 1.1642219 (220)\ttotal: 4m\tremaining: 23m 12s\n",
      "240:\tlearn: 0.8913020\ttest: 1.1616959\tbest: 1.1616959 (240)\ttotal: 4m 21s\tremaining: 22m 45s\n",
      "260:\tlearn: 0.8835901\ttest: 1.1588234\tbest: 1.1588234 (260)\ttotal: 4m 42s\tremaining: 22m 22s\n",
      "280:\tlearn: 0.8752334\ttest: 1.1570654\tbest: 1.1568697 (275)\ttotal: 5m 5s\tremaining: 22m 5s\n",
      "300:\tlearn: 0.8690603\ttest: 1.1544420\tbest: 1.1544420 (300)\ttotal: 5m 26s\tremaining: 21m 42s\n",
      "320:\tlearn: 0.8632124\ttest: 1.1533111\tbest: 1.1533111 (320)\ttotal: 5m 49s\tremaining: 21m 22s\n",
      "340:\tlearn: 0.8578731\ttest: 1.1526561\tbest: 1.1523282 (335)\ttotal: 6m 11s\tremaining: 21m 1s\n",
      "360:\tlearn: 0.8534280\ttest: 1.1514317\tbest: 1.1514317 (360)\ttotal: 6m 33s\tremaining: 20m 40s\n",
      "380:\tlearn: 0.8483435\ttest: 1.1501692\tbest: 1.1500850 (379)\ttotal: 6m 56s\tremaining: 20m 22s\n",
      "400:\tlearn: 0.8433886\ttest: 1.1480848\tbest: 1.1480848 (400)\ttotal: 7m 19s\tremaining: 20m 4s\n",
      "420:\tlearn: 0.8385863\ttest: 1.1471638\tbest: 1.1471638 (420)\ttotal: 7m 42s\tremaining: 19m 46s\n",
      "440:\tlearn: 0.8347075\ttest: 1.1463007\tbest: 1.1461840 (438)\ttotal: 8m 6s\tremaining: 19m 28s\n",
      "460:\tlearn: 0.8313326\ttest: 1.1454521\tbest: 1.1454521 (460)\ttotal: 8m 30s\tremaining: 19m 9s\n",
      "480:\tlearn: 0.8278588\ttest: 1.1453962\tbest: 1.1450395 (473)\ttotal: 8m 51s\tremaining: 18m 46s\n",
      "500:\tlearn: 0.8247634\ttest: 1.1443239\tbest: 1.1443239 (500)\ttotal: 9m 14s\tremaining: 18m 25s\n",
      "520:\tlearn: 0.8217300\ttest: 1.1441039\tbest: 1.1438464 (511)\ttotal: 9m 37s\tremaining: 18m 5s\n",
      "bestTest = 1.143846389\n",
      "bestIteration = 511\n",
      "Shrink model to first 512 iterations.\n",
      "fold : 1\n",
      "{'train size': 9889879, 'eval size': 9889878}\n",
      "0:\tlearn: 1.9708477\ttest: 1.9962103\tbest: 1.9962103 (0)\ttotal: 1.08s\tremaining: 27m 6s\n",
      "20:\tlearn: 1.1989787\ttest: 1.3200421\tbest: 1.3200421 (20)\ttotal: 22.5s\tremaining: 26m 26s\n",
      "40:\tlearn: 1.0965783\ttest: 1.2509049\tbest: 1.2509049 (40)\ttotal: 42.9s\tremaining: 25m 25s\n",
      "60:\tlearn: 1.0531317\ttest: 1.2227305\tbest: 1.2227305 (60)\ttotal: 1m 3s\tremaining: 25m 7s\n",
      "80:\tlearn: 1.0227677\ttest: 1.2057335\tbest: 1.2057335 (80)\ttotal: 1m 25s\tremaining: 24m 58s\n",
      "100:\tlearn: 0.9996129\ttest: 1.1937138\tbest: 1.1933655 (99)\ttotal: 1m 47s\tremaining: 24m 55s\n",
      "120:\tlearn: 0.9799305\ttest: 1.1867438\tbest: 1.1867438 (120)\ttotal: 2m 10s\tremaining: 24m 46s\n",
      "140:\tlearn: 0.9638273\ttest: 1.1808068\tbest: 1.1808068 (140)\ttotal: 2m 32s\tremaining: 24m 31s\n",
      "160:\tlearn: 0.9498457\ttest: 1.1762031\tbest: 1.1762031 (160)\ttotal: 2m 54s\tremaining: 24m 11s\n",
      "180:\tlearn: 0.9371130\ttest: 1.1735270\tbest: 1.1735270 (180)\ttotal: 3m 18s\tremaining: 24m 4s\n",
      "200:\tlearn: 0.9269601\ttest: 1.1697965\tbest: 1.1697965 (200)\ttotal: 3m 41s\tremaining: 23m 48s\n",
      "220:\tlearn: 0.9167455\ttest: 1.1681455\tbest: 1.1679670 (217)\ttotal: 4m 4s\tremaining: 23m 32s\n",
      "240:\tlearn: 0.9066727\ttest: 1.1667469\tbest: 1.1664370 (235)\ttotal: 4m 28s\tremaining: 23m 20s\n",
      "260:\tlearn: 0.8977310\ttest: 1.1651001\tbest: 1.1651001 (260)\ttotal: 4m 50s\tremaining: 22m 58s\n",
      "280:\tlearn: 0.8907328\ttest: 1.1638952\tbest: 1.1638952 (280)\ttotal: 5m 13s\tremaining: 22m 39s\n",
      "300:\tlearn: 0.8835084\ttest: 1.1636151\tbest: 1.1634539 (299)\ttotal: 5m 35s\tremaining: 22m 18s\n",
      "320:\tlearn: 0.8776327\ttest: 1.1616118\tbest: 1.1616118 (320)\ttotal: 6m\tremaining: 22m 2s\n",
      "340:\tlearn: 0.8717993\ttest: 1.1610272\tbest: 1.1605905 (334)\ttotal: 6m 23s\tremaining: 21m 42s\n",
      "bestTest = 1.160590455\n",
      "bestIteration = 334\n",
      "Shrink model to first 335 iterations.\n",
      "oof_RMSE :  1.1522488189579954\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 2\n",
    "kf = KFold(n_splits=2, shuffle=False, random_state=1024)\n",
    "models = []\n",
    "oof = np.zeros(len(df_train))\n",
    "samples = len(df_train)//2\n",
    "for i  in range(2):\n",
    "    print('fold :', i)\n",
    "    if i == 0:\n",
    "        tr_x, tr_y = df_train[features].iloc[:samples], df_train[target][:samples]\n",
    "        vl_x, vl_y = df_train[features].iloc[samples:], df_train[target][samples:]\n",
    "    else:\n",
    "        vl_x, vl_y = df_train[features].iloc[:samples], df_train[target][:samples]\n",
    "        tr_x, tr_y = df_train[features].iloc[samples:], df_train[target][samples:]\n",
    "    print({'train size':len(tr_x), 'eval size':len(vl_x)})\n",
    "    \n",
    "    dtrain = Pool(tr_x, label=tr_y, cat_features=category)\n",
    "    dvalid = Pool(vl_x, label=vl_y, cat_features=category) \n",
    "    del tr_x, tr_y, vl_y\n",
    "    gc.collect()\n",
    "    cat_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'learning_rate': 0.09,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'loss_function': 'RMSE',\n",
    "    'random_seed': 100,\n",
    "    'metric_period': 10,\n",
    "    'task_type': 'GPU',\n",
    "    'depth': 10,\n",
    "    }\n",
    "    model = CatBoostRegressor(**cat_params)\n",
    "    model = model.fit(\n",
    "        dtrain, eval_set=dvalid,\n",
    "        use_best_model=True,\n",
    "        verbose=20,\n",
    "        early_stopping_rounds=20)\n",
    "    model.save_model('catboost_fold_%s.bin'%i)\n",
    "    if i == 0:\n",
    "        oof[samples:] = model.predict(vl_x)\n",
    "    else:\n",
    "        oof[:samples] = model.predict(vl_x)\n",
    "    models.append(model)\n",
    "    del vl_x, dtrain, dvalid\n",
    "    gc.collect()\n",
    "    \n",
    "print('oof_RMSE : ' ,np.sqrt(mean_squared_error(oof, df_train['meter_reading'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['oof'] = oof\n",
    "df_train[['oof']].to_csv('oof_c1.csv', index=False)\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models = []\n",
    "for i in range(2):\n",
    "    model = CatBoostRegressor()\n",
    "    model.load_model('catboost_fold_%s.bin'%i)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_test = pd.read_csv('/kaggle/input/ashrae-energy-prediction/test.csv', parse_dates=['timestamp'])\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "\n",
    "df_test = df_test.merge(building_metadata, on='building_id', how='left')\n",
    "df_test = df_test.merge(weather, on=['site_id', 'timestamp'], how='left')\n",
    "del building_metadata, weather\n",
    "gc.collect()\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "\n",
    "#time variable\n",
    "df_test[\"timestamp\"] = pd.to_datetime(df_test[\"timestamp\"])\n",
    "df_test[\"hour\"] = df_test[\"timestamp\"].dt.hour\n",
    "df_test[\"weekend\"] = df_test[\"timestamp\"].dt.weekday\n",
    "df_test['year_built'] = df_test['year_built']-1900\n",
    "df_test['square_feet'] = np.log1p(df_test['square_feet'])\n",
    "\n",
    "df_test['is_holiday'] = (df_test['timestamp'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "del df_test[\"timestamp\"]\n",
    "\n",
    "# split test data into batches\n",
    "set_size = len(df_test)\n",
    "iterations = 50\n",
    "batch_size = set_size // iterations\n",
    "\n",
    "print(set_size, iterations, batch_size)\n",
    "assert set_size == iterations * batch_size\n",
    "\n",
    "meter_reading = []\n",
    "for i in tqdm_notebook(range(iterations)):\n",
    "    pos = i*batch_size\n",
    "    fold_preds = [np.expm1(model.predict(Pool(df_test[features].iloc[pos : pos+batch_size], cat_features=category))) for model in models]\n",
    "    meter_reading.extend(np.mean(fold_preds, axis=0))\n",
    "\n",
    "print(len(meter_reading))\n",
    "assert len(meter_reading) == set_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_submission['meter_reading'] = np.clip(meter_reading, a_min=0, a_max=None) # clip min at zero\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
